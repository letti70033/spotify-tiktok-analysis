{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The TikTok-to-Spotify Pipeline\n",
    "**TXC Group X**<br>\n",
    "Leticia Brendle - 70033 <br>\n",
    "Francesco Ciorciolini - 73166 <br>\n",
    "X<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repository: https://github.com/letti70033/spotify-tiktok-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*notes from prof (sheet):*\n",
    "The Notebook must include at least the following sections:\n",
    "1. Executive Summary – A short summary that highlights the goal of the project and core findings.\n",
    "2. Introduction – A section that describes (in words) the dataset and variables. This section should\n",
    "clearly state the research question(s) and the related hypotheses and describe a plan to test them.\n",
    "3. Exploratory data analysis – A section that uses different statistical metrics and visualizations to\n",
    "describe the data set and presents the first descriptive insights.\n",
    "4. Method 1 – This section should describe why a specific method (e.g., t-test, linear regression,\n",
    "logistic regression, cluster analysis, factor analysis, time series model, or panel regression) is used\n",
    "to test a hypothesis. It should apply the method to the data set, check the most important\n",
    "assumptions, and provide an interpretation of the results obtained (i.e., what did we learn about\n",
    "the hypotheses, and how good is the model).\n",
    "5. Method 2 – This section should contain the same information as the previous section, but with\n",
    "another method to test a different hypothesis.\n",
    "6. Reflection on use of AI – This section is dedicated to discussing the use of AI, should detail what\n",
    "AI models were used, for what tasks AI was used, how it was used (e.g., prompt examples), and\n",
    "what value the students contributed beyond the tasks the AI completed (e.g., what instructions\n",
    "were crucial to improve the quality of the project, what approaches did not work, etc.).\n",
    "7. Conclusion – This section should discuss the findings and explain what we learned about the\n",
    "research question. Further, it should discuss the chosen approach's limitations and ways to\n",
    "improve the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Introduction\n",
    "\n",
    "### 2.1 Dataset\n",
    "\n",
    "### 2.2 Variables\n",
    "\n",
    "### 2.3 Research Question\n",
    "\"Does TikTok virality create a 'popularity ceiling' effect? Investigating how TikTok engagement patterns predict and limit long-term streaming success across Spotify.\"\n",
    "\n",
    "*Why Novel: Tests the counterintuitive idea that TikTok success might actually limit rather than enhance long-term success*\n",
    "*Business Relevance: Critical for music industry investment and artist development strategies*\n",
    "\n",
    "\n",
    "### 2.4 Hypotheses\n",
    "\n",
    "H1: Songs with extremely high TikTok engagement (top 10%) show diminishing returns on Spotify long-term streaming compared to moderate TikTok performers\n",
    "\n",
    "H2: The TikTok-Spotify conversion rate follows an inverted U-shape, with optimal TikTok engagement existing in the middle range\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Methods: Polynomial regression to test non-linear relationships + threshold analysis for identifying optimal TikTok engagement levels -> see if we use this methods!!*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Import Libraries and Data\n",
    "-> set up with libraries and get initial feeling of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Graphs\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Statistics\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "# Data\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# Graphs\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Statistics\n",
    "import scipy.stats as stats\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "# Load CSV file \n",
    "songs_spotify = pd.read_csv('Most Streamed Spotify Songs 2024.csv', encoding='cp1252')\n",
    "\n",
    "# Data Overview \n",
    "print(songs_spotify.head())\n",
    "print(f\"Dataset size: {songs_spotify.shape[0]} rows, {songs_spotify.shape[1]} columns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Data Cleaning\n",
    "\n",
    "clean data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Drop unnecessary columns\n",
    "\n",
    "we dont need columns: X, just:'Track', 'Artist', 'Release Date',\n",
    "    'Spotify Streams', 'Spotify Popularity', 'Spotify Playlist Count', \n",
    "    'TikTok Posts', 'TikTok Likes', 'TikTok Views',\n",
    "    'Track Score', 'All Time Rank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping 11 relevant columns from 29 total columns:\n",
      "  • Track\n",
      "  • Artist\n",
      "  • Release Date\n",
      "  • Spotify Streams\n",
      "  • Spotify Popularity\n",
      "  • Spotify Playlist Count\n",
      "  • TikTok Posts\n",
      "  • TikTok Likes\n",
      "  • TikTok Views\n",
      "  • Track Score\n",
      "  • All Time Rank\n",
      "                        Track          Artist Release Date Spotify Streams  \\\n",
      "0         MILLION DOLLAR BABY   Tommy Richman    4/26/2024     390,470,936   \n",
      "1                 Not Like Us  Kendrick Lamar     5/4/2024     323,703,884   \n",
      "2  i like the way you kiss me         Artemas    3/19/2024     601,309,283   \n",
      "3                     Flowers     Miley Cyrus    1/12/2023   2,031,280,633   \n",
      "4                     Houdini          Eminem    5/31/2024     107,034,922   \n",
      "\n",
      "   Spotify Popularity Spotify Playlist Count TikTok Posts   TikTok Likes  \\\n",
      "0                92.0                 30,716    5,767,700    651,565,900   \n",
      "1                92.0                 28,113      674,700     35,223,547   \n",
      "2                92.0                 54,331    3,025,400    275,154,237   \n",
      "3                85.0                269,802    7,189,811  1,078,757,968   \n",
      "4                88.0                  7,223       16,400            NaN   \n",
      "\n",
      "     TikTok Views  Track Score All Time Rank  \n",
      "0   5,332,281,936        725.4             1  \n",
      "1     208,339,025        545.9             2  \n",
      "2   3,369,120,610        538.4             3  \n",
      "3  14,603,725,994        444.9             4  \n",
      "4             NaN        423.3             5  \n",
      "\n",
      "Dataset after dropping columns: 4600 rows, 11 columns\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define TikTok-to-Spotify relevant columns\n",
    "relevant_columns = [\n",
    "    'Track', 'Artist', 'Release Date',\n",
    "    'Spotify Streams', 'Spotify Popularity', 'Spotify Playlist Count', \n",
    "    'TikTok Posts', 'TikTok Likes', 'TikTok Views',\n",
    "    'Track Score', 'All Time Rank'\n",
    "]\n",
    "\n",
    "print(f\"Keeping {len(relevant_columns)} relevant columns from {songs_spotify.shape[1]} total columns:\")\n",
    "for col in relevant_columns:\n",
    "    print(f\"  • {col}\")\n",
    "\n",
    "# drop other columns\n",
    "songs_clean_columns = songs_spotify[relevant_columns].copy()\n",
    "\n",
    "#overview of data with relevant columns\n",
    "print(songs_clean_columns.head())\n",
    "print(f\"\\nDataset after dropping columns: {songs_clean_columns.shape[0]} rows, {songs_clean_columns.shape[1]} columns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Remove missing values\n",
    "\n",
    "find and remove missing values + make all data to coherent types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "  Track: 0 (0.0%)\n",
      "  Artist: 5 (0.1%)\n",
      "  Release Date: 0 (0.0%)\n",
      "  Spotify Streams: 113 (2.5%)\n",
      "  Spotify Popularity: 804 (17.5%)\n",
      "  Spotify Playlist Count: 70 (1.5%)\n",
      "  TikTok Posts: 1173 (25.5%)\n",
      "  TikTok Likes: 980 (21.3%)\n",
      "  TikTok Views: 981 (21.3%)\n",
      "  Track Score: 0 (0.0%)\n",
      "  All Time Rank: 0 (0.0%)\n",
      "\n",
      "Rows before dropping missing values: 4600\n",
      "Rows after dropping missing values: 3171\n",
      "Total number of missing values dropped: 1429\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# see how many/where missing values there are\n",
    "missing_summary = songs_clean_columns.isnull().sum()\n",
    "missing_percentage = (missing_summary / len(songs_clean_columns)) * 100\n",
    "\n",
    "print(\"Missing values per column:\")\n",
    "for col in songs_clean_columns.columns:\n",
    "    missing_count = missing_summary[col]\n",
    "    missing_pct = missing_percentage[col]\n",
    "    print(f\"  {col}: {missing_count} ({missing_pct:.1f}%)\")\n",
    "\n",
    "# identify numeric columns\n",
    "numeric_columns = [\n",
    "    'Spotify Streams', 'Spotify Popularity', 'Spotify Playlist Count',\n",
    "    'TikTok Posts', 'TikTok Likes', 'TikTok Views', \n",
    "    'Track Score', 'All Time Rank'\n",
    "]\n",
    "\n",
    "# convert string numbers to int\n",
    "for col in numeric_columns:\n",
    "    if col in songs_clean_columns.columns:\n",
    "        # remove , \n",
    "        songs_clean_columns[col] = songs_clean_columns[col].astype(str).str.replace(',', '').str.replace(' ', '')\n",
    "        songs_clean_columns[col] = pd.to_numeric(songs_clean_columns[col], errors='coerce')\n",
    "\n",
    "# Release Date to datetime\n",
    "songs_clean_columns['Release Date'] = pd.to_datetime(songs_clean_columns['Release Date'], errors='coerce')\n",
    "\n",
    "# Drop rows with missing values+ Overview\n",
    "bef_mis_values = len(songs_clean_columns)\n",
    "print(f\"\\nRows before dropping missing values: {bef_mis_values}\")\n",
    "songs_clean_missing_na = songs_clean_columns.dropna()\n",
    "aft_mis_values = len(songs_clean_missing_na)\n",
    "print(f\"Rows after dropping missing values: {aft_mis_values}\")\n",
    "print(f\"Total number of missing values dropped: {bef_mis_values-aft_mis_values}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 Remove Duplicates\n",
    "\n",
    "Checking for duplicates based on Track + Artist combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate songs found: 12\n",
      "\n",
      "Duplicated songs:\n",
      "  'Bad and Boujee (feat. Lil Uzi Vert)' by Migos: 2 entries\n",
      "  'Cheap Thrills' by Sia: 2 entries\n",
      "  'Dembow' by Danny Ocean: 2 entries\n",
      "  'Let Her Go' by Passenger: 2 entries\n",
      "  'Me Rehï¿½ï' by Danny Ocean: 2 entries\n",
      "Remaining duplicates after dropping: 0\n",
      "\n",
      "Rows before dropping duplicateds: 3171\n",
      "Rows after dropping duplictes: 3159\n",
      "Total number of duplicates dropped: 12\n",
      "\n",
      "Cleaned dataset saved as 'spotifysongs_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#check for duplictes based on Track + Artist combination\n",
    "duplicates_before = songs_clean_missing_na.duplicated(subset=['Track', 'Artist']).sum()\n",
    "bef_dupl = len(songs_clean_missing_na)\n",
    "\n",
    "print(f\"Duplicate songs found: {duplicates_before}\")\n",
    "\n",
    "if duplicates_before > 0:\n",
    "    \n",
    "    print(\"\\nDuplicated songs:\")\n",
    "    duplicate_songs = songs_clean_missing_na[songs_clean_missing_na.duplicated(subset=['Track', 'Artist'], keep=False)]\n",
    "    duplicate_examples = duplicate_songs.groupby(['Track', 'Artist']).size().head()\n",
    "    for (track, artist), count in duplicate_examples.items():\n",
    "        print(f\"  '{track}' by {artist}: {count} entries\")\n",
    "    \n",
    "    # drop duplicates\n",
    "    bef_dupl = len(songs_clean_missing_na)\n",
    "    songs_clean_duplicates = songs_clean_missing_na.drop_duplicates(subset=['Track', 'Artist'], keep='first')\n",
    "    aft_dupl = len(songs_clean_duplicates)\n",
    "else:\n",
    "    print(\"No duplicates found!\")\n",
    "\n",
    "\n",
    "# Overview of dropped duplicates\n",
    "duplicates_after = songs_clean_duplicates.duplicated(subset=['Track', 'Artist']).sum()\n",
    "print(f\"Remaining duplicates after dropping: {duplicates_after}\")\n",
    "print(f\"\\nRows before dropping duplicateds: {bef_dupl}\")\n",
    "print(f\"Rows after dropping duplictes: {aft_dupl}\")\n",
    "print(f\"Total number of duplicates dropped: {bef_dupl - aft_dupl}\")\n",
    "\n",
    "# Save cleaned dataset\n",
    "songs_clean_duplicates.to_csv('spotify_cleaned.csv', index=False)\n",
    "print(f\"\\nCleaned dataset saved as 'spotifysongs_cleaned.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
